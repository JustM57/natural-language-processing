{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Подход 2\n",
    "Тут будет использован finetuning готовой [модели](https://huggingface.co/Helsinki-NLP/opus-mt-ru-en)\n",
    "В качестве примера был использован [ноутбук](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb) из huggungface\n",
    "* Была переделана обработка датасета, чтобы был нужный формат\n",
    "* Были натроены гиперпараметры модели(warmup, scheduler, смягчение лейблов)\n",
    "* Был настроен паддинг внутри батча(по дефолту почему-то id=-100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-ru-en\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "STEP 1: Prepare_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "def prepare_dataset(path_to_data: str, ratio: List[float] = (0.8, 0.15, 0.05)):\n",
    "    data = pd.read_csv(path_to_data, header=None, sep='\\t')\n",
    "    data.columns = ['en', 'ru']\n",
    "    left_border = 0\n",
    "    res = {}\n",
    "    for name, size in [('train', ratio[0]), ('validation', ratio[1]), ('test', ratio[2])]:\n",
    "        split_data = data.iloc[int(data.shape[0] * left_border): int(data.shape[0] * (left_border + size))]\n",
    "        split_data = {'translation': [{'en': row['en'], 'ru': row['ru']} for idx, row in split_data.iterrows()]}\n",
    "        res[name] = Dataset.from_dict(split_data)\n",
    "        left_border += size\n",
    "    return DatasetDict(res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "\n",
    "raw_datasets = prepare_dataset(path_do_data)\n",
    "metric = load_metric(\"sacrebleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 40000\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 7500\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2500\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'translation': {'en': 'Cordelia Hotel is situated in Tbilisi, a 3-minute walk away from Saint Trinity Church.',\n  'ru': 'Отель Cordelia расположен в Тбилиси, в 3 минутах ходьбы от Свято-Троицкого собора.'}}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>translation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'en': 'The property offers free parking.', 'ru': 'На территории гостевого дома обустроена бесплатная парковка.'}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'en': 'Offering an outdoor pool and a fitness centre, Guest House Albatros is located in Dagomys. Free WiFi access is available.', 'ru': 'Гостевой дом «Альбатрос» находится в поселке Дагомыс. К услугам гостей открытый бассейн, фитнес-центр и бесплатный WiFi.'}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'en': 'Parking near the property is free.', 'ru': 'Неподалеку от апартаментов есть бесплатная парковка.'}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'en': 'Berggasthof Haldenhof offers a sauna and regional cuisine.', 'ru': 'В гостевом доме Berggasthof Haldenhof вы сможете воспользоваться сауной и отведать блюда региональной кухни.'}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'en': 'The 3-star Hotel Ladenmühle offers spacious, comfortably furnished rooms with modern amenities, including free wireless internet access and lovely views.', 'ru': 'К услугам гостей 3-звездочного отеля Ladenmühle просторные комфортабельные номера с живописным видом и современными удобствами, включая бесплатный Wi-Fi.'}</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(raw_datasets[\"train\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используется стандартный токенайзер и модель"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[902, 7680, 573, 2, 21, 537, 2674, 25, 171, 144, 4008, 6287, 56, 0], [1089, 471, 2674, 21, 2674, 13, 3876, 537, 402, 144, 4008, 6287, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"ru\"\n",
    "target_lang = \"en\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "prefix=\"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[1110, 2390, 367, 29508, 3345, 3934, 19488, 6, 47980, 2, 6, 165, 3732, 1004, 6706, 426, 3118, 58, 17808, 70, 11, 29595, 70, 53, 14700, 57, 193, 3952, 41, 3, 0], [49, 608, 95, 260, 1304, 15412, 4290, 7033, 1089, 918, 1798, 14450, 9656, 6405, 818, 17330, 20088, 21, 20603, 41, 4324, 7, 16, 141, 12215, 11, 15071, 3, 324, 1001, 388, 6987, 1002, 84, 12780, 2045, 2799, 7, 43070, 6, 5054, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[19713, 20981, 3934, 23312, 34, 25144, 10, 45870, 2, 13, 165, 11, 32721, 6441, 1449, 65, 15697, 53405, 16788, 3, 0], [552, 18492, 20148, 27540, 68, 10485, 136, 7923, 33, 85, 1052, 13, 598, 11, 19543, 4438, 14556, 2, 2318, 1405, 2, 8, 13, 43729, 6399, 3, 0]]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets['train'][:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad4f71996c3b42b1ab1b6ff2bc53eb3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/8 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c2e0a2dc3784cf78849534520607d2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02db6c423a4b4b4f9bce4f08bd5c4749"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(62518, 512, padding_idx=62517)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(62518, 512, padding_idx=62517)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(62518, 512, padding_idx=62517)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=62518, bias=False)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 76,147,712 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "batch_size = 30 \n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    warmup_steps=1000,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=15,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=6,\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.01,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    model=model, \n",
    "    label_pad_token_id=tokenizer.pad_token_id\n",
    ") # паддит инпуты и лейблы внутри батча"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "/home/dmitry/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 40000\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 30\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 30\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='20010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/20010 : < :, Epoch 0.00/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-1334] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-2668] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-4002] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-5336] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-8004] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-9338] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-16008/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-10672] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-17342/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-12006] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-18676/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-13340] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 30\n",
      "Saving model checkpoint to opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010\n",
      "Configuration saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010/config.json\n",
      "Model weights saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-ru-en-finetuned-ru-to-en/checkpoint-20010/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-ru-en-finetuned-ru-to-en/checkpoint-14674] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from opus-mt-ru-en-finetuned-ru-to-en/checkpoint-6670 (score: 0.5945083498954773).\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=20010, training_loss=0.4568776904672816, metrics={'train_runtime': 7391.2026, 'train_samples_per_second': 81.178, 'train_steps_per_second': 2.707, 'total_flos': 1.063842450112512e+16, 'train_loss': 0.4568776904672816, 'epoch': 15.0})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/84 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_datasets[\"test\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'test_loss': 0.6019531488418579,\n 'test_bleu': 39.3273,\n 'test_gen_len': 21.0808,\n 'test_runtime': 95.8882,\n 'test_samples_per_second': 26.072,\n 'test_steps_per_second': 0.876}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "generated_text = tokenizer.batch_decode(preds.predictions, skip_special_tokens=True)\n",
    "original_text = tokenizer.batch_decode(preds.label_ids, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated: Set in the centre of Kovachevitsa, Pension Ristevata offers a garden with free barbecue facilities and free luggage storage.\n",
      "original: Ristevata Guest House enjoys a central location in Kovachevitsa and offers a garden with free barbecue facilities and free luggage storage.\n",
      "generated: Guests can visit the on-site restaurant bar with a private beach, just 300 metres away.\n",
      "original: A bar restaurant, featuring its own private beach area, is just 300 metres away.\n",
      "generated: There is a 24-hour front desk at the property.\n",
      "original: The front desk is available 24/7.\n",
      "generated: Set in Brasov, this apartment features a balcony with mountain views.\n",
      "original: Set in Braşov, this apartment features a balcony with mountains views.\n",
      "generated: Apartment Volguntes Street is located in a quiet residential green area of Riga, 5 km from the city centre.\n",
      "original: Apartment Volguntes Street is housed in a quiet and green residential district of Riga, within 5 km from the city centre.\n",
      "generated: A wardrobe and flat-screen TV are also included.\n",
      "original: They also come with a wardrobe and a flat-screen TV.\n",
      "generated: The Palace of Government is 15.3 km away.\n",
      "original: Palacio de Gobierno is 15.3 km away.\n",
      "generated: They have tiled floors and windows with mosquito nets.\n",
      "original: They also feature tiled floors and a mosquito net.\n",
      "generated: Rooms at the Almhof are decorated with natural wood furniture and carpeted or parquet floors.\n",
      "original: The Almhofs rooms are decorated with natural wood furniture and carpeted or parquet floors.\n",
      "generated: An Italian-style breakfast is provided daily and includes homemade cakes, cereals and freshly baked croissants.\n",
      "original: An Italian-style breakfast is offered daily, with homemade cakes, cereals and freshly-baked croissants.\n"
     ]
    }
   ],
   "source": [
    "random_idx = np.random.choice(len(generated_text), 10)\n",
    "for idx in random_idx:\n",
    "    print(f\"generated: {generated_text[idx]}\\noriginal: {original_text[idx]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По семплам видно, что перевод прекрасный. Текст хорошо читается. Из каких-то явных минусов - поскольку модель является char-level, то в именах нарицательных есть опечатки.\n",
    "Что касаемо метрик - они великолпные. Впрочем, это объяснимо тем, что сама по себе модель уже с первой же итерации показывает отличный скор."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}